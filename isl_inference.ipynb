{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb08ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee25a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('isl_neural_network.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48033369",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [str(num) for num in range(1, 10)]\n",
    "letter_list = [chr(letter) for letter in range(ord('A'), ord('Z') + 1)]\n",
    "action_labels = num_list + letter_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6c5b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "single = [0]*63\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands.Hands(static_image_mode=False, max_num_hands=1)\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d03e325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results = mp_hands.process(frame_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "        landmarks = []\n",
    "        for landmark in hand_landmarks.landmark:\n",
    "            landmarks.append(landmark.x)\n",
    "            landmarks.append(landmark.y)\n",
    "            landmarks.append(landmark.z)\n",
    "#         \n",
    "        \n",
    "        if len(landmarks)==63:\n",
    "            landmarks = landmarks + single\n",
    "\n",
    "#             landmarks = np.concatenate((landmarks,single),axis=1)\n",
    "        landmarks = np.array(landmarks)\n",
    "        landmarks = np.reshape(landmarks, (1, 126, 1))\n",
    "\n",
    "        # Perform action classification using the LSTM model\n",
    "        predictions = model.predict(landmarks)\n",
    "        predicted_action = action_labels[np.argmax(predictions)]\n",
    "        \n",
    "        # Draw landmarks and action label on the frame\n",
    "#         mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "#                                   mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=4),\n",
    "#                                   mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2))\n",
    "        cv2.putText(frame, predicted_action, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 2.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Hand Action Recognition\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and destroy windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a87f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d9fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabe2dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
